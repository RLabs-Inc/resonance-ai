# Resonance-AI Configuration Template
# Copy this file to resonance-ai.config.yaml and fill in your values
# This configuration is optimized for Claude's development workflow

# Project settings
project:
  name: 'resonance-ai'
  rootPath: '/Users/rusty/Documents/Projects/AI/Tools/GuardianAI'
  exclude:
    - 'node_modules'
    - 'dist'
    - 'build'
    - '.git'
    - '*.log'
    - 'coverage'
    - '.nyc_output'
    - '*.tmp'
  include:
    - '**/*.ts'
    - '**/*.tsx'
    - '**/*.js'
    - '**/*.jsx'
    - '**/*.json'
    - '**/*.md'
    - '**/*.yaml'
    - '**/*.yml'

# Indexing configuration
indexing:
  languages: ['typescript', 'javascript']
  maxFileSize: 1000000 # 1MB
  debounceMs: 500
  parseComments: true
  generateHashes: true

# Context compilation settings
context:
  maxFiles: 20
  maxLinesPerFile: 200
  relevanceThreshold: 0.3
  includePatterns: true
  includeArchitecture: true
  includeTests: false

# Pattern recognition settings
patterns:
  autoDetect: true
  customPatterns: './patterns'
  confidenceThreshold: 0.7
  maxPatterns: 50

# Brief generation settings
briefing:
  templatePath: './templates'
  includeExamples: true
  includeConstraints: true
  verboseGuidance: false
  maxBriefLength: 10000

# Interface settings (optimized for Claude)
interface:
  theme: 'dark'
  verbose: false
  autoRefresh: true
  shortcuts:
    switchView: 'tab'
    refresh: 'r'
    help: '?'
    quit: 'q'

# Performance settings
performance:
  cacheSize: 100
  maxMemoryMB: 512
  gcIntervalMs: 30000

# API Configuration for Self-Communication
api:
  anthropic:
    # REQUIRED: Set your Anthropic API key here
    # Get your API key from: https://console.anthropic.com/
    apiKey: "YOUR_ANTHROPIC_API_KEY_HERE"
    model: "claude-3-5-sonnet-20241022"
    maxTokens: 4096
    temperature: 0.1
  
  # Enable Resonance-AI to call itself for advanced reasoning
  selfCommunication:
    enabled: true
    endpoint: "https://api.anthropic.com/v1/messages"
    systemPrompt: "You are Resonance-AI, helping your past self with development tasks."